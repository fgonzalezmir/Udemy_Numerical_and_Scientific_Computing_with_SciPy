{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "div#notebook, div.CodeMirror, div.output_area pre, div.output_wrapper, div.promp\n",
       "t {\n",
       "  font-family: 'Inconsolata', monospace !important;\n",
       "  font-size: 14px;\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       "#notebook_panel { /* main background */\n",
       "    background: rgb(245,245,245);\n",
       "}\n",
       "\n",
       "div.cell { /* set cell width */\n",
       "    width: 850px;\n",
       "}\n",
       "\n",
       "div #notebook { /* centre the content */\n",
       "    background: #fff; /* white background for content */\n",
       "    width: 1000px;\n",
       "    margin: auto;\n",
       "    padding-left: 0em;\n",
       "}\n",
       "\n",
       "#notebook li { /* More space between bullet points */\n",
       "margin-top:0.8em;\n",
       "}\n",
       "\n",
       "/* draw border around running cells */\n",
       "div.cell.border-box-sizing.code_cell.running { \n",
       "    border: 1px solid #111;\n",
       "}\n",
       "\n",
       "/* Put a solid color box around each cell and its output, visually linking them*/\n",
       "div.cell.code_cell {\n",
       "    background-color: rgb(256,256,256); \n",
       "    border-radius: 0px; \n",
       "    padding: 0.5em;\n",
       "    margin-left:1em;\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render{\n",
       "    font-family: 'Alegreya Sans' sans-serif;\n",
       "    line-height: 140%;\n",
       "    font-size: 125%;\n",
       "    font-weight: 400;\n",
       "    width:700px;\n",
       "    margin-left:auto;\n",
       "    margin-right:auto;\n",
       "}\n",
       "\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-style:regular;\n",
       "    font-weight: 400;    \n",
       "    font-size: 45pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.5em;\n",
       "    margin-top: 0.5em;\n",
       "    display: block;\n",
       "}\t\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 30pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.3em;\n",
       "    display: block;\n",
       "}\t\n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    margin-top:16px;\n",
       "\tfont-size: 22pt;\n",
       "    font-weight: 600;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: regular;\n",
       "    color: rgb(102,102,0);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {    /*Use this for captions*/\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-size: 14pt;\n",
       "    text-align: center;\n",
       "    margin-top: 0em;\n",
       "    margin-bottom: 2em;\n",
       "    font-style: regular;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {  /*Use this for small titles*/\n",
       "    font-family: 'Nixie One', sans-serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 16pt;\n",
       "    color: rgb(163,0,0);\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.8em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 { /*use this for copyright note*/\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 9pt;\n",
       "    line-height: 100%;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".CodeMirror{\n",
       "        font-family: \"PT Mono\";\n",
       "        font-size: 90%;\n",
       "}\n",
       "\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"],\n",
       "                           equationNumbers: { autoNumber: \"AMS\", useLabelIds: true}\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "#css_file = '../../../style/style03my.css'\n",
    "css_file = '../../../style/style01.css'\n",
    "HTML(open(css_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### [Sergio Rojas](http://prof.usb.ve/srojas)<br>\n",
    "[Departamento de F&iacute;sica](http://www.fis.usb.ve/), [Universidad Sim&oacute;n Bol&iacute;var](http://www.usb.ve/), [Venezuela](http://es.wikipedia.org/wiki/Venezuela)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Content under [Creative Commons Attribution license CC-BY 4.0](http://creativecommons.org/licenses/by/4.0/), [code under MIT license (c)](http://en.wikipedia.org/wiki/MIT_License)2016-2017 Sergio Rojas (srojas@usb.ve).###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Image(filename='./img/ex_regression.png', width=720, height=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HTML('<iframe src=https://en.wikipedia.org/wiki/Mathematical_optimization width=700 height=350></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Image(filename='./Volume_2_Video_2.1_figs/vol2_v21_0x_Jderivatives.png', width=720, height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The squared error cost function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "        {\\textbf h}(\\mathbf{\\theta}) = \\theta_0 {\\textbf X}_0 + \\theta_1 {\\textbf X}_1 + \\theta_2 {\\textbf X}_2 + \\cdots + \\theta_n {\\textbf X}_n =       \n",
    "%        \n",
    "\\begin{pmatrix} {\\textbf X}_0 \\; {\\textbf X}_1 \\; {\\textbf X}_2 \\; \\cdots \\; {\\textbf X}_n \\end{pmatrix}\n",
    "        \\begin{pmatrix}\\theta_0 \\\\\n",
    "                       \\theta_1 \\\\\n",
    "                       \\theta_2 \\\\\n",
    "                       \\vdots \\\\\n",
    "                       \\theta_n \\end{pmatrix}\n",
    "        %\n",
    "        \\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "        J(\\theta) &= \\frac{1}{2m}\\sum_{i=1}^m \\left[ h^{(i)}(\\theta)-y^{(i)}\\right]^2 \\\\\n",
    "                  &= \\frac{1}{2m}\\sum_{i=1}^m \\left[ \\theta_0 X_0^{(i)} + \\theta_1 X_1^{(i)} + \\theta_2 X_2^{(i)} + \\cdots + \\theta_n X_n^{(i)} - y^{(i)}\\right]^2,\n",
    "        \\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "       X = \n",
    "        \\begin{pmatrix}\n",
    "               X_0^{(1)} \\quad X_1^{(1)} \\quad X_2^{(1)} \\quad \\cdots \\quad X_n^{(1)} \\\\\n",
    "               X_0^{(2)} \\quad X_1^{(2)} \\quad X_2^{(2)} \\quad \\cdots \\quad X_n^{(2)} \\\\\n",
    "               X_0^{(3)} \\quad X_1^{(3)} \\quad X_2^{(3)} \\quad \\cdots \\quad X_n^{(3)} \\\\\n",
    "                \\vdots   \\quad  \\vdots   \\quad \\vdots    \\quad \\vdots \\quad \\vdots  \\\\\n",
    "               X_0^{(m)} \\quad X_1^{(m)} \\quad X_2^{(m)} \\quad \\cdots \\quad X_n^{(m)}\n",
    "         \\end{pmatrix}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computing the J cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def JcostF(theta, X, y):\n",
    "    #----\n",
    "    # In this function it is computed the J squared error cost function\n",
    "    # or the function to which the minimum is going to be found\n",
    "    #\n",
    "    # The input parameters are the data points defining the function\n",
    "    #      \n",
    "    #       X : as a column matrix \n",
    "    #       y : as a column vector\n",
    "    #   theta : the parameters fitting the model\n",
    "    #\n",
    "    # Author: Sergio Rojas\n",
    "    #----\n",
    "    import numpy as np\n",
    "    m = len(y) # number of training examples\n",
    "    #\n",
    "    h = np.dot(X,theta) # also: X.dot(theta)\n",
    "    square = (h-y)**2\n",
    "    J = 1.0/(2.0*m) * np.sum(square)\n",
    "    #\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Gradient Descent algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\theta_k = \\theta_k - \\alpha \\frac{\\partial J(\\theta)}{\\!\\!\\!\\! \\partial \\theta_k}, \n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Derivatives of the squared error cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\\begin{aligned}\n",
    "\\begin{pmatrix} \n",
    "             \\frac{\\partial J(\\theta)}{\\!\\!\\!\\! \\partial \\theta_0} \\\\ \n",
    "             \\frac{\\partial J(\\theta)}{\\!\\!\\!\\! \\partial \\theta_1} \\\\\n",
    "             \\frac{\\partial J(\\theta)}{\\!\\!\\!\\! \\partial \\theta_2} \\\\ \n",
    "                        \\vdots \\\\\n",
    "             \\frac{\\partial J(\\theta)}{\\!\\!\\!\\! \\partial \\theta_n} \n",
    "         \\end{pmatrix} =\n",
    "   \\frac{1}{m}\\left[ \\mathbf{-X}^{\\rm T} \\mathbf y+ (\\mathbf X^{\\rm T} \\mathbf X ){\\boldsymbol{\\theta}} \\right]   =\n",
    "   \\frac{1}{m}\\mathbf{X}^{\\rm T} \\left[ \\mathbf X {\\boldsymbol{\\theta}} - \\mathbf y  \\right]\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Our implementation of Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GradientDescent(X, y, theta, alpha, MAX_ITERS=1000, tolerance = 1e-05 ):\n",
    "    #----\n",
    "    # In this function it is computed the gradient descent algorithm\n",
    "    # that updates the thetas:\n",
    "    #\n",
    "    # The input parameters:\n",
    "    #      \n",
    "    #       X : as a column matrix \n",
    "    #       y : as a column vector\n",
    "    #   theta : the parameters fitting the model\n",
    "    #   alpha : the learning rate\n",
    "    #  \n",
    "    # Author: Sergio Rojas\n",
    "    #----\n",
    "    import numpy as np\n",
    "    m = len(y) # number of training examples\n",
    "    J = np.array([])\n",
    "    tol = 1\n",
    "    k = 0\n",
    "    while (tol > tolerance) and (k <= MAX_ITERS):\n",
    "        k = k + 1\n",
    "        h = np.dot(X,theta)\n",
    "        temp = np.dot(np.transpose(h-y),X)\n",
    "        temp = np.transpose(temp)        \n",
    "        oldtheta = theta\n",
    "        theta = theta - (alpha/m)*temp\n",
    "        tol = np.sum(np.abs(theta-oldtheta))        \n",
    "        J = np.append( J, JcostF(theta, X, y) ) \n",
    "        #tol = np.abs( JcostF(oldtheta, X, y) - JcostF(theta, X, y) )\n",
    "    if k >= MAX_ITERS:\n",
    "      print('WARNING!!!')\n",
    "      print('A number of {0} iterations (>= MAX_ITERS) was reached'.format(k))\n",
    "      print('you might want rerun the code using the reported  values for theta. \\n')\n",
    "    else:\n",
    "        print('\\t Convergence was reached after {0} iterations. \\n'.format(k))\n",
    "\n",
    "    return theta, J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### An example testing our implementation of Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      " [[ 1.  0.]\n",
      " [ 1.  1.]\n",
      " [ 1.  2.]\n",
      " [ 1.  3.]\n",
      " [ 1.  4.]\n",
      " [ 1.  5.]\n",
      " [ 1.  6.]\n",
      " [ 1.  7.]\n",
      " [ 1.  8.]\n",
      " [ 1.  9.]]\n",
      "y =  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "X = np.column_stack((np.ones(10), np.arange(10)))\n",
    "y = np.arange(10)\n",
    "print('X = \\n',X)\n",
    "print('y = ',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Convergence was reached after 563 iterations. \n",
      "\n",
      "theta = [  5.99002573e-04   9.99904474e-01]\n"
     ]
    }
   ],
   "source": [
    "theta0 = np.array([2.,2.]) # initial guess\n",
    "th, J = GradientDescent(X, y, theta0, 0.05)\n",
    "print('theta =',th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Solving the problem using SciPy linear regression function](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.stats.linregress.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept = 0.0 slope = 1.0\n"
     ]
    }
   ],
   "source": [
    "# check with scipy linear regression \n",
    "from scipy import stats\n",
    "slope, intercept, rvalue, pvalue, stderror = stats.linregress(X[:,1], y)\n",
    "print ( ('intercept = {0} slope = {1}').format(intercept, slope) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Solving the problem using SciPy optimize functions](https://docs.scipy.org/doc/scipy-0.18.1/reference/optimize.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "         Gradient evaluations: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  7.93900408e-08,   9.99999988e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "optimize.fmin_cg(JcostF, x0=[2, 2],args=(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 9.261894271726636e-16\n",
       "     jac: array([  3.48835160e-08,   2.40535063e-07])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 20\n",
       "     nit: 2\n",
       "    njev: 5\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([  7.93900408e-08,   9.99999988e-01])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize.minimize(JcostF, x0=[2, 2],args=(X,y), method='CG', jac=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -8.13233676e-07,   1.00000012e+00]),\n",
       " 9.594604562818161e-14,\n",
       " {'funcalls': 30,\n",
       "  'grad': array([ -2.48270185e-07,   2.93838812e-08]),\n",
       "  'nit': 7,\n",
       "  'task': b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL',\n",
       "  'warnflag': 0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize.fmin_l_bfgs_b(JcostF, x0=[2, 2],args=(X,y),approx_grad=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 9.594604562818161e-14\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ -2.48270185e-07,   2.93838812e-08])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 30\n",
       "      nit: 7\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ -8.13233676e-07,   1.00000012e+00])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize.minimize(JcostF, x0=[2, 2],args=(X,y), method='L-BFGS-B', jac=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>References</font> #\n",
    "\n",
    "Additional discussion and examples can be found at:\n",
    "\n",
    "- [Scipy Lecture Notes: Mathematical optimization: finding minima of functions](http://www.scipy-lectures.org/advanced/mathematical_optimization/)\n",
    "- [SciPy Cookbook: Optimization and fitting](http://scipy-cookbook.readthedocs.io/items/idx_optimization_and_fitting.html)\n",
    "- [Differential Evolution](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.optimize.differential_evolution.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Content under [Creative Commons Attribution license CC-BY 4.0](http://creativecommons.org/licenses/by/4.0/), [code under MIT license (c)](http://en.wikipedia.org/wiki/MIT_License)2016-2017 Sergio Rojas (srojas@usb.ve). ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
